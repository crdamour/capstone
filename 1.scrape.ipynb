{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import string\n",
    "import bs4\n",
    "\n",
    "def partial_txt(b, txt, p = True):\n",
    "    '''Finds elements by their link text. User enters webdriver browser object and partial text.\n",
    "    Defaults to finding all elements p (for plural) equals true. User can change to False to find\n",
    "    first element'''\n",
    "    return b.find_elements_by_partial_link_text(txt) if p else b.find_element_by_partial_link_text(txt)\n",
    "\n",
    "def tag_name(b, tag, p = True):\n",
    "    '''Finds elements by their tag name. It will find all elements if the default p (plural) argument is True.'''\n",
    "    return b.find_elements_by_tag_name(tag) if p else b.find_element_by_tag_name(tag)\n",
    "\n",
    "def class_name(b, tag, p = True):\n",
    "    '''Finds an element by its class name. Finds all elements if the default p (plural) argument is True.'''\n",
    "    return b.find_elements_by_class_name(tag) if p else b.find_element_by_class_name(tag)\n",
    "\n",
    "def contribute(b):\n",
    "    '''Checks if contribute-home pop-up is up, which prompts user to contribute their salary.'''\n",
    "    keywords = ['contribute', 'submit']\n",
    "    url_end = b.current_url.split('/')[-1]\n",
    "    result = [True if k in url_end.lower() else False for k in keywords]\n",
    "    return True if any(result) else False\n",
    "\n",
    "def last_window(b):\n",
    "    '''Switches active window to last active window.'''\n",
    "    b.switch_to.window(b.window_handles[-1])\n",
    "\n",
    "def splt_punct(w, p):\n",
    "    '''Helper function to split column names on punctuation.'''\n",
    "    res = None\n",
    "    for l in w:\n",
    "        if l in p:\n",
    "            res = w.split(l)\n",
    "            #Want it to break after finding first occurrence of punctuation in the word.\n",
    "            break\n",
    "    return w if not res else res\n",
    "\n",
    "def iter_get_att(b, tag, **kwargs):\n",
    "    '''Helper function supporting iteration of data to see if an attribute name is equal to a value.'''\n",
    "    res = None\n",
    "    for x in tag_name(b, tag):\n",
    "        boo = [True if v and x.get_attribute(k) == v else False for (k, v) in kwargs.items()]\n",
    "        if all(boo) and len(boo) == len(kwargs):\n",
    "            res = x\n",
    "            break\n",
    "    return res\n",
    "\n",
    "##Haven't tested yet\n",
    "def pagination_flow(b):\n",
    "    pgs = {'class': 'pagination'}\n",
    "    looking_for = iter_get_att(b, 'ul', **pgs)\n",
    "    pages = [tag_name(tn, 'a', p = False) for tn in tag_name(looking_for, 'li')]\n",
    "    #Make below cleaner with a dict and then use dict comp to finalize.\n",
    "    pagination = {k: pages[v] for (k, v) in {'left': 0, 'right': -1, 'min': 1, 'max': -2}.items()}\n",
    "    return pagination\n",
    "\n",
    "def job_information(b, tag):\n",
    "    '''Grabs job information per page. Returns job_dictionary with name key and selenium obj value.'''\n",
    "    dropdown = tag_name(b, tag, p = False)\n",
    "    dropdown.click()\n",
    "    jobs = tag_name(dropdown, 'option')\n",
    "    job_dict = {j.text: jobs[i] for (i, j) in enumerate(jobs)}\n",
    "    dropdown.click()\n",
    "    return job_dict\n",
    "\n",
    "def rows_pp(b, number = '100'):\n",
    "    '''Selects the number of rows in the levels.fyi table per page. Default is 100. Note: This is one\n",
    "    function that can be vastly improved and/or can lead on other funcs (like iter_get_att).'''\n",
    "    rows_dropdown = None\n",
    "    for t in tag_name(b, 'button'):\n",
    "        class_type = t.get_attribute('class')\n",
    "        if class_type == 'btn btn-default dropdown-toggle':\n",
    "            spn = tag_name(t, 'span')\n",
    "            if spn:\n",
    "                rows_dropdown = spn[0]\n",
    "    rows_dropdown.click()\n",
    "    rows_per_page = {}\n",
    "    for t in tag_name(b, 'ul'):\n",
    "        c = t.get_attribute('class')\n",
    "        if c == 'dropdown-menu':\n",
    "            lis = tag_name(t, 'li')\n",
    "            for l in lis:\n",
    "                rows_per_page[l.text] = l\n",
    "    rows_per_page[number].click()\n",
    "    \n",
    "def add_dict_list(d, k, v):\n",
    "    '''Helper function to add items to list in df dictionary. Keys already exist.'''\n",
    "    existing = d[k]\n",
    "    existing.append(v)\n",
    "    d[k] = existing\n",
    "    \n",
    "def extract_table(rs, cnames, b):\n",
    "    '''Extracts tables from the tables of compensation data on levels.fyi site.'''\n",
    "    #A dict to hold result values.\n",
    "    df_cols = {nc: [] for nc in cnames}\n",
    "    #Tagging on additional attributes not derived from the table itself.\n",
    "    df_cols = {**df_cols, **{'Gender': [], 'Race': [], 'Academic': []}}\n",
    "    #Since index 0 is the colnames above.\n",
    "    for r in rs[1:]:\n",
    "        #Columns\n",
    "        cols = r.find_all('td')\n",
    "        comp, loc_dt = cols[1].text.split('\\n')\n",
    "        add_dict_list(df_cols, 'Company', comp)\n",
    "        loc, dt = loc_dt.split(' | ')\n",
    "        add_dict_list(df_cols, 'Location', loc)\n",
    "        add_dict_list(df_cols, 'Date', dt)\n",
    "        level, tag = cols[2].text.split('\\n')\n",
    "        if len(level) > 0:\n",
    "            add_dict_list(df_cols, 'Level Name', level)\n",
    "        else:\n",
    "            add_dict_list(df_cols, 'Level Name', '')\n",
    "        if len(tag) > 0:\n",
    "            add_dict_list(df_cols, 'Tag', tag)\n",
    "        else:\n",
    "            add_dict_list(df_cols, 'Tag', '')\n",
    "        yrs_comp, yrs_exp = cols[3].text.split(' / ')\n",
    "        add_dict_list(df_cols, 'Years at Company', yrs_comp)\n",
    "        add_dict_list(df_cols, 'Years of Experience', yrs_exp)\n",
    "        c_breakdown = False\n",
    "        for x in cols[-1].find_all('span'):\n",
    "            if x.text:\n",
    "                if '|' in x.text:\n",
    "                    c_breakdown = True\n",
    "                    base, stock, bonus = x.text.split(' | ')\n",
    "                    add_dict_list(df_cols, 'Base', base)\n",
    "                    add_dict_list(df_cols, 'Stock', stock)\n",
    "                    add_dict_list(df_cols, 'Bonus', bonus)\n",
    "                elif '$' in x.text:\n",
    "                    total_comp = x.text\n",
    "                    add_dict_list(df_cols, 'Total Compensation', total_comp)\n",
    "        if not c_breakdown:\n",
    "            add_dict_list(df_cols, 'Base', '')\n",
    "            add_dict_list(df_cols, 'Stock', '')\n",
    "            add_dict_list(df_cols, 'Bonus', '')\n",
    "    \n",
    "    #Asking selenium to find tables now to begin clicking on rows to grab extra data.\n",
    "    tab_sel = b.find_elements_by_tag_name('table')\n",
    "    #Not all tables have rows - similar to comment above.\n",
    "    row_sel = tab_sel[1].find_elements_by_tag_name('tr')\n",
    "    #Since row zero is column names.\n",
    "    for rs in row_sel[1:]:\n",
    "        cols_sel = rs.find_elements_by_tag_name('td')\n",
    "        if cols_sel:\n",
    "            cols_sel[3].click()\n",
    "    #Using beautiful soup again to grab the data more quickly....\n",
    "    soup2 = bs4.BeautifulSoup(b.page_source, 'lxml')\n",
    "    #Finding the table with bs.\n",
    "    s2 = soup2.find_all('table')[1]\n",
    "    #Looking at gender if available.\n",
    "    for s in s2.find_all('span', {'class': 'gender-info'}):\n",
    "        try:\n",
    "            #Some values are text as integers. Making sure ignore.\n",
    "            int(s.text)\n",
    "        except ValueError:\n",
    "            add_dict_list(df_cols, 'Gender', s.text)\n",
    "    #Looking at Race and Academics if available.\n",
    "    for s in s2.find_all('div', {'class': 'company-details'}):\n",
    "        t = s.find_all('p', {'style': 'padding-left: 40px; padding-right: 40px; white-space: normal;'})\n",
    "        for y in t:\n",
    "            txt = y.text\n",
    "            if 'Race' in txt:\n",
    "                res = txt.split(':')\n",
    "                ind = [res.index(i) for i in res if i.endswith('Race')][0]\n",
    "                ind_plus = ind + 1\n",
    "                if ',' in res[ind_plus]:\n",
    "                    r, nada = res[ind_plus].split(',')\n",
    "                    add_dict_list(df_cols, 'Race', r.strip())\n",
    "                else:\n",
    "                    add_dict_list(df_cols, 'Race', res[ind_plus].strip())\n",
    "            else:\n",
    "                add_dict_list(df_cols, 'Race', '')\n",
    "            if 'Academic' in txt:\n",
    "                res = txt.split(':')\n",
    "                add_dict_list(df_cols, 'Academic', res[-1].strip())\n",
    "            else:\n",
    "                add_dict_list(df_cols, 'Academic', '')\n",
    "    \n",
    "    df = pd.DataFrame(df_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing browser object.\n",
    "levels_url = 'https://www.levels.fyi/'\n",
    "b = webdriver.Firefox()\n",
    "b.get(levels_url)\n",
    "\n",
    "#Finding the View Salaries button to select it and begin looking for compensation data.\n",
    "#Only one of these on the page so setting argument to false.\n",
    "sal = partial_txt(b, 'View Salaries', p = False)\n",
    "sal.click()\n",
    "\n",
    "# #Moving to new active window.\n",
    "last_window(b)\n",
    "\n",
    "# #Popup window will come up asking for salary. Sleeping to allow to come up. Truncating it from url\n",
    "# #and moving to new url to stick to grabbing data. 20 seconds sleep seems to be enough.\n",
    "sleep(20)\n",
    "if contribute(b):\n",
    "    b.get(b.current_url.split('#')[0])\n",
    "    \n",
    "# #Since switched again to another url have to switch to new url.\n",
    "last_window(b)\n",
    "\n",
    "#------Eliminating geography filters. Only need to do this once------\n",
    "\n",
    "#Finding button to start eliminating any filters on geography for view salaries search.\n",
    "geog_dropd = {'data-toggle': 'dropdown', 'aria-haspopup': 'true'}\n",
    "button = iter_get_att(b, 'button', **geog_dropd)\n",
    "button.click()\n",
    "\n",
    "#Getting menu object that identifies if any geography items are checked.\n",
    "menu_drop = {'class': 'dropdown-menu dropdown-menu-right'}\n",
    "menu = iter_get_att(b, 'ul', **menu_drop)\n",
    "\n",
    "#Takes off any geographic filters in dropdown menu.\n",
    "geog_filt = {'class': 'filter-by-region-menu'}\n",
    "divs = iter_get_att(menu, 'li', **geog_filt)\n",
    "#Can likely implement iter_get_att() again here, but not sure if really saves me space/time.\n",
    "for d in tag_name(divs, 'div'):\n",
    "    if d.get_attribute('class') == 'checkbox':\n",
    "        inp = tag_name(d, 'input')\n",
    "        if inp[0].get_attribute('checked'):\n",
    "            inp[0].click()\n",
    "#To close menu.                    \n",
    "button.click()\n",
    "\n",
    "#----------Setting up list of available jobs in the dropdown----------May need to do more than once.\n",
    "\n",
    "job_dict = job_information(b, 'select')\n",
    "\n",
    "#-----Setting rows per page displayed-----Have not implement iter_get_att() here. May write better code.---\n",
    "\n",
    "#Perhaps start this section after job dict above. Writing below as if after job_dict above.\n",
    "\n",
    "job_titles = list(job_dict.keys())\n",
    "\n",
    "# new_colnames = None\n",
    "new_colnames = []\n",
    "\n",
    "dfs = []\n",
    "\n",
    "errors = set()\n",
    "\n",
    "#For each job in the dropdown.\n",
    "for jt in job_titles:\n",
    "    \n",
    "    #Some jobs don't have enough data. In this case, we'll skip them and keep track of them.\n",
    "    no_data = tag_name(b, 'h3', p = False)\n",
    "    if no_data.text == \"Let's get paid fairly\":\n",
    "        job_dict = job_information(b, 'select')\n",
    "        next_job = job_dict[job_titles[job_titles.index(jt) + 1]]\n",
    "        next_job.click()\n",
    "        continue\n",
    "        \n",
    "    #Setting row number to 100 since when change jobs it reverts back to 10.\n",
    "    rows_pp(b)\n",
    "    \n",
    "    #Obtaining pagination.\n",
    "    pagination = pagination_flow(b)\n",
    "    #Max number of pages per job in list.\n",
    "    number_pages = int(pagination['max'].text)\n",
    "    \n",
    "    #Start with fewer amount of pages if want to test.\n",
    "#     for p in range(0, 1):\n",
    "    for p in range(0, number_pages):\n",
    "        soup1 = bs4.BeautifulSoup(b.page_source, 'lxml')\n",
    "        tab = soup1.find_all('table')\n",
    "        #Multiple tables on the page. Index one is the one that has the data needed.\n",
    "        rows = tab[1].find_all('tr')\n",
    "        #Setting up column names.\n",
    "        if not new_colnames:\n",
    "            punct = list(string.punctuation)\n",
    "            #First row at index zero is colnames.\n",
    "            cn = [v for v in rows[0].text.split('\\n') if v != '']\n",
    "            colnames = []\n",
    "            for v in cn:\n",
    "                p = False\n",
    "                for l in v:\n",
    "                    if l in punct:\n",
    "                        p = True\n",
    "                        colnames.append(v.split(l))\n",
    "                        break\n",
    "                if not p:\n",
    "                    colnames.append(v)\n",
    "            for c in colnames:\n",
    "                if isinstance(c, list):\n",
    "                    for x in c:\n",
    "                        new_colnames.append(x.strip())\n",
    "                else:\n",
    "                    new_colnames.append(c)\n",
    "        #In case there is select missing data.\n",
    "        try:\n",
    "            df = extract_table(rows, new_colnames, b)\n",
    "            #Adding job title to the df.\n",
    "            df.loc[:, 'Job'] = jt\n",
    "            dfs.append(df)\n",
    "        except:\n",
    "            #Adding job title and page to reference if cannot adequately collect data.\n",
    "            errors.add((jt, p))\n",
    "        \n",
    "        #Next page.\n",
    "        pagination['right'].click()\n",
    "        #Resetting pagination since on a new page.\n",
    "        pagination = pagination_flow(b)\n",
    "        #sleep(1)\n",
    "    #After finish first job need to switch to next. Will be on new page, so need to get new element.\n",
    "    if jt == job_titles[-1]:\n",
    "        break\n",
    "    job_dict = job_information(b, 'select')\n",
    "    next_job = job_dict[job_titles[job_titles.index(jt) + 1]]\n",
    "    next_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
